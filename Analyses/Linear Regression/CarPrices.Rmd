---
title: "Car Prices"
output: 
  html_document:
    theme: cerulean
    code_folding: hide
---
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(pander)
library(car)
```
<br>

## Background

I have data for cars which include the price, mileage, model, trim, type, the number of cylinders, the number of liters, how many doors and whether not it has a sound system and a leather interior. I will use this data to see if I can do a multiple linear regression to predict the price of a Chevy Impala based off of the mileage and trim of the car.



```{r, include=FALSE}
# Be sure to download the CarPrices.csv file and save it
# into your Data folder prior to knitting this file.
CarPrices <- read.csv("../../Data/CarPrices.csv", header=TRUE)

impalas <- CarPrices %>% filter(Model == "Impala")

# Remember, to get the CarPrices data into your Console you have
# to use the "Import Dataset" option in the "Environment" window.
```


## Questions and Hypotheses

Question : Can knowing the milage and trim of a Chevy Impala predict its price?

Hypotheses : 

Beta1 is the slope of the mileage variable.

Beta2 is the slope of the trim variable.

1) Null Hypotheses : Beta1 and Beta2 are equal to zero.
2) Alternative Hypotheses: Beta1 and Beta2 are not equal to zero.

## Analysis

```{r, warning=FALSE}

price_lm <- lm(Price ~ Mileage + Trim, data = impalas)
pander(summary(price_lm))

```

##### For this test we will use an alpha of 0.05

The p-values for this test are all less than 0.05 so we can accept our alternative hypotheses that the slopes are not equal to zero. The R squared value is 0.9725 which tells us that there is a very strong linear relationship in the data.




```{r, warning=FALSE}

par(mfrow=c(1,3))
plot(price_lm, which=1)
qqPlot(price_lm$residuals, id=FALSE)
plot(price_lm$residuals)

```

This is a plot of the residuals and the qq plot to check for normality. We see that the residuals look good and the data is normal so we can check off the requirments for linear regression analysis.

1) There seems to be a linear relationship. 
2) The error terms seem to be normaly distributed.
3) The variance is constant.
4) The x values are measured and fixed without error.
5) The error terms are independent.

## Graphical Summary

```{r, warning=FALSE}

ggplot(data = impalas, mapping = aes(x = Mileage, y = Price, color = factor(Trim))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Mileage vs Price", x = "Mileage", y = "Price in Dollars", color = "trim") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "bottom")
  



```

Here we can double check visualy that our data is linear and we see that strong linear relationship. It looks like this multiple linear regression model will be a great predictor for price.

## Interpretation and Conclusion

It looks like I can accurately predict the price of a Chevy Impala based off of my analysis. I should start a competitor to "Kelley Blue Book".


